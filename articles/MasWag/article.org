# -*- truncate-lines: nil; -*-
#+TODO: TODO | DONE POSTPONED
#+TITLE: 複数マシンでの実験を Ansible とかでシュっとした話 — 実験編
#+AUTHOR: MasWag
#+EMAIL: masakiwaga@gmail.com
#+OPTIONS: ^:{}
#+LANG: ja

* はじめに

皆さん実験ぶん回してますか？アルゴリズムを設計する人は勿論ですが、そうでない人も諸々のチューニングをして高速化をするとき、複数手法を比較して選定するとき、実験することは少なくないと思います。実験すると言うのは簡単ですが、色々な組み合わせで試そうとするとかなり長い時間がかかることもあるので、あまり気軽に実験を回せない人も少なくないと思います。

しかし今はクラウドコンピューティングの時代です! 各マシンで完全に独立な実験を回す場合、N 台のマシンで実験を回せば 基本的には 1/N の時間で実験が終わることになります。特に Amazon Web Services (AWS), Microsoft Azure, Google Cloud Platform (GCP)等 クラウドの場合、多くの場合料金計算が 時間 $\times$ 台数なので、 台数を増やしてもその分時間が減れば、なんと料金的には変わらないです。

とは言ったものの複数台のマシンで大量に実験を回すのは一苦労です。実験するマシンの調達、実験するマシンの環境構築、実験タスクの各マシンへの分配、実験結果の回収方法、等々考える必要のある作業は多数あります。この辺りの作業で手間取ると無駄にクラウドの料金が増えてしまうので悲しいです。一方で、よくあるクラウドでの複数台管理についての情報は、「同じ働きをする」マシンを複数台立ててロードバランサ等でタスクを分配する、Webアプリケーション向けのものが殆どなので、そのまま並列実験に適用できないことが多いです。

この文章では、複数マシンで実験を回す方法についての説明をします。内容としてはクラウドを意識はしていますが、大半の内容はオンプレミス環境などでも動作するはずです。また、今回の実験はAWSで行ないましたが、AWSに特化した話題は極力避けています。例えばAWSではオンデマンドインスタンスで所謂「定価」で計算資源を買うよりも、スポットインスタンスでオークション形式で買った方が安いですが、そういった話はしません。また、この文章で説明している手法は単なる一例にすぎません。「僕の考えた最強の手法」ですらなく、今回の実験をそれなりの労力で「シュっとさせた」というだけなので改善の余地は多いにあります。一方で他の人がこういう実験をどういう風に回しているのかを知りたい、というニーズに答えられていれば幸いです。

** おことわり

今回の文章中に挙げているスクリプトですが、比較的やっつけで書いたものも少なくないのでポータビリティについてはあんまり自信がないです。特に Arch Linux や macOS + Homebrew などの、比較的最新版に近いコマンドラインツールがインストールされる環境で確動作確認を行なっているので、ややバージョンの古めのUbuntuなどでは上手く動作しないかもしれません。

関連した本やブログ記事などがあれば良いのですが、筆者の知る限りでは似たことをやっている文書は見つかりませんでした。御存じの方が居たら教えていただけると参考になります。また技術選定については完全に筆者の好みです。他の例えば全体的にpythonに統一する、など別の方法も可能ですし、そういった方法と比べて今回の方法が優れているかどうかは一概には言えないでしょう。

* 基本方針

今回の実験ではおおよそ以下の様なことを基本方針としています。

- できるだけ自動化させるが、諸々のコストが大きい場合は手動作業も厭わない (KISSの原則)
- できるだけ実験を行なった環境・コマンドの情報を残しておく (再現性の担保)

** できるだけ自動化させるが、諸々のコストが大きい場合は手動作業も厭わない

人類皆自動化大好きですし、勿論僕も好きです。特に多数のマシンの管理を行なう際に手動の作業が多いと手間ですし、手動で色々やって時間がかかるとクラウドの従量課金額が増えてしまうのでシンプルに勿体ないです。そもそもこの記事のタイトルにある Ansible はマシンの構成を自動で管理するツールですし、自動化は行ないます。

しかし、だからと言って全ての作業の自動化はこの記事でのゴールではありません。行き過ぎた自動化によって構築するシステムが複雑すぎるものになってしまうのは考えものです。構築するシステムが複雑になればなるほどデバッグは大変になりますし、本当にやりたい実験に到達するまでの時間が長くなってしまいます。今回の最終目的は自分のやりたい実験を簡単に回すことなのでその上で大きな障壁とならない部分はできるだけシンプルに、場合によっては手動作業で行ないます。

** できるだけ実験を行なった環境・コマンドの情報を残しておく

比較的大規模な実験をする上でとても気がかりなことの一つは、正しい手順で実験をやっているかどうかだと思います。複数の設定で実験をやっていると =git clone= 等でバージョンを変更するのを忘れる、コンパイルを忘れるなどのオペレーションミスが起きる (または起きていないか段々自信がなくなってくる) と思います。

もう一つの大きな懸念事項は実験環境を忘れてしまうということです。一つ一つの実験について、例えば gcc のコンパイルオプションが =-O3= だったか =-O2= だったかを人間が覚えていくのはなかなか難しいですし、自分が書いたソフトウェアの細かいバージョンと実験結果の対応関係は、ちゃんと記録を残しておかないとまずわからなくなってしまうでしょう。

これらの理由で過去に行なった実験自体の正しさに確信が持てない場合、つまり「そういえばこの実験ってどういう環境でやったんだっけ…?」という状況になってしまった場合、最終的には再実験を行なって「正しい」実験を再度行なうことになると思います。大規模な実験となると時間もかかりますし、クラウドで行なうととお金もかかってしまいます。特に時間を置いて新しい環境と比較実験を行ないたい場合には、過去の実験環境の詳細がわかっていない場合には再実験が必要になると思われます。

こういった問題を起こさないためにも、できるだけ実験を行なった環境・コマンドの情報を残しておく、つまり同じ実験を再現させられるようにしておく、ということは今回の実験では重視します。

** COMMENT 具体的には実験スクリプト + 実験対象のGit revisionを残していく
*** 本当はマシンスペック (AWSならインスタンスタイプ) とか OSとかもスクリプトで残せると良いが、難しい場合はテキストで残しても良い


* イカれたメンバーを紹介するぜ!!

- マシンの作成 :: 手動!!
- マシンの起動 :: vmctl!!
- 構成管理 :: Ansible!!
- 実験スクリプト、実験結果の管理 :: Git!!
- 対話的な諸々の自動化 :: expect!!
- 実験開始・終了のお知らせ :: slack!!

以上!!

# この問題があるのでPDFの画像をorg-modeで書けない https://github.com/jgm/pandoc/issues/5454
#+BEGIN_EXPORT satysfi
+figure ?:(`flowchart`) {実験全体のワークフロー} <
  +image-frame {
    \insert-pdf-image(14.5cm)(`./MasWag/figs/flowchart.pdf`)(1);
  }
>
#+END_EXPORT

ここから各登場ツールについて説明をしていきます。なお、最終的なワークフローは \ref-figure(`flowchart`); の様になります。

** vmctl
:PROPERTIES:
:CUSTOM_ID: my-headline-2
:END:

*vmctl* (https://github.com/MasWag/vmctl) は様々な仮想マシンに対して同様のインターフェースで起動、停止などの基本的な操作を行なえる様にした、手製のshell scriptです。「様々な仮想マシン」と言いつつ現状Amazon AWSの EC2 と VirtualBox にしか対応していないですが、原理的にはコマンドラインインターフェースが用意されている仮想マシンであればそれなりの工数で追加できることになっています。

今回は特に複数種類の仮想マシンを扱うこともないと思いますが、マシンのidを毎回打ちたくないという理由で使いました。例えばec2だと各マシン (インタンス) に対して =i-1234567890abcdef0= の様なidが割り振られます。率直に言うとこれは人間が覚えて直接扱うべきものではありません。できるものなら各マシンに役割の分かり易い名前を付けたり、例えば =my_instance1 my_instance2 my_instance3 ...= の様に連番のマシン名を付けたりしたいです。今回のvmctlの用途は正にこの名前付けです。例えばマシン名が =my_great_instance= のマシンを起動するのであれば、 =vmctl start my_great_instance= で起動できますし。特にMachine名が連番である場合は bashの連番展開を使って、例えば =vmctl stop my_instance{1..10}= の様に使うこともできます。

*** 代替品 -- Terraform

クラウドのマシンを一括で起動・停止するという意味では Terraform を使うこともできます。Terraform は 必要なインスタンス等のインフラストラクチャをテキストで定義して、自動で作成 (apply) ・破棄 (destroy) するツールです。Terraform を使う場合は予め準備しておいたインスタンスを起動・停止するのではなく、毎回新しいインスタンスを作成・破棄することになるので、よりImmutable Infrastructure的なワークフローに向いていると思います。なお、筆者がTerraformを使うときはPackerとAnsibleで大元のイメージを作成しています。

** Ansible

*Ansible* (https://www.ansible.com/) は言わずと知れた超有名構成管理ツールで、YAMLでマシンの設定を記述することで、自動で環境構築やデプロイを行えるツールです。今回は必要なソフトウェアのインストールの他に、実験スクリプトや実験用のコードの入っているgitレポジトリの clone/pull等に使っています。実験対象のプログラムのコンパイル等の定型処理を忘れない、というのも一つの利点ですが、Ansible は複数マシンに対して実行することができるので、特に多くのマシンを扱いたい場合には便利になります。

*** 代替品 -- 構成管理ツール

Ansible 以外にも例えば以下に挙げた様に、構成管理ツールはかなり多数あるので、好きなものを使うと良いと思います。個人的にも Ansible を使っている深い理由はないですし、色々な比較をしているwebページもかなりあるので、ここでは名前を挙げるのみとします。

- itamae
- Chef
- Puppet

** Git

*Git* (https://git-scm.com/) は有名、というより2020年現在ほぼデファクトスタンダードとなっている分散バージョン管理システムです。今回はGitを実験内容を記述したスクリプトの管理だけではなく、実験結果のテキストファイルの管理にも使っています。実験スクリプトはソフトウェアなので当然Gitでの版管理は便利ですが、実験結果もGitで管理しているのは、複数マシンで実験を行なった結果、生成されたファイルが衝突したときにちゃんとマージできるからです。この、「複数マシンで同時に実験した結果を上手い具合にマージできる」という点が並列実験システムにおいてかなり重要であると考えています。

*** 代替品 -- バージョン管理システム

Git以外にもMercurialやBazaar、darcsなど様々な分散バージョン管理システムがあるので、これも好きなものを選ぶと良いと思います。一方バージョン管理システムと言っても、RCSの様にローカルで完結しているものや、Subversionの様に集中型で気軽にマージができないものは向かないと思います。

複数マシン間でデータを同期させたいだけであれば、例えば rsync でも良い様に思えますが、過去の変更の情報をちゃんと追えなかったりmergeがちゃんとできないので、しっかりとワークフローを練らないと代替は難しいと思います。

*** 速度面での課題

Gitはかなり大きなレポジトリを扱えますが、実験ログが膨大になったり、特に巨大なバイナリファイルを多数扱う必要が出てくると Git が思う様に動かなくなっていきます。具体的には例えば =git merge= などにかなりの時間がかかる様になります。これについては、 (筆者は試したことがないですが) 例えば Git-LFS を使うことで全体のワークフローとの噛み合わせを保ちつつ巨大なファイルを扱える様になると思われます。

** expect

*expect* (https://core.tcl-lang.org/expect/index) はTcl製の対話的なCUIプログラムの自動化ツールです。普通のCUIの処理の自動化なら例えばシェルスクリプトで行なえますが、例えばsshやftp等で必要となる対話的な操作の自動化をシェルスクリプトで行なうのは至難の技です。(例えばbash 4.0で追加されたコプロセスを使えば実現できそうな気がします。)こういった場面でexpectを使うことで比較的用意に自動化することができます。今回は実験スクリプトをリモートで実行する際にexpectを使いました。ansible でも似たことができるかもしれないですが、知らないうちにオーバーヘッドが載って実験結果に影響があると良くないので、できるだけ簡素な方法ということでexpectを使いました。

*** 代替品

今回はオリジナルのTcl版のexpectを使いましたが、pythonやrubyなどでもexpectの移植版や類似のものが出ているので、そちらを使っても良いでしょう。

** slack

*slack* (https://slack.com) は有名チャットツールで、http経由で簡単に外部から通知を送ることができます。今回は実験終了の通知を送るために使いました。実験の進め方とは関係ないですが、実験が終わるのかを逐一見に行くのは精神衛生上よろしくないですし、今回のワークフローの中では重要だと考えます。

*** 代替品

今回はslackを単に通知を送るためだけに使っているので、特にslackである必要もないですし、普段slackを使っていない人がわざわざ使う必要はないでしょう。他のチャットツールを使っても良いですし、それこそメールで通知を送っても大丈夫です。

** COMMENT コマンドラインのデータ処理ツール datamash
*** TSV, CSVファイルから平均とか分散とか統計情報を計算できる
*** Pivotingして 人が読めるテーブルを作る


* マシン構成パート

ここから、マシン構成パートの流れについて説明していきます。

** マシンの作成・初期設定 (手動)

まず始めに実験に使うマシンを作成して、ユーザ設定や最低限必要な設定などを行ないます。「マシンの初期設定」というとかなり広い範囲のことが含まれそうですが、環境構築スクリプトをもう一度回せば同じ環境を構築できる様にしたいので、できる限り手動操作を減らすと良いでしょう。例えば今後必要となるユーザやSSH鍵の配置といったアクセス周りの設定や、今後の実験で必要なソフトウェアで、毎回インストールするのが時間や手間の上で大変なものだけを設定するのが良いと思います。逆にインストールに時間や手間がかかるソフトウェアを毎回インストールするのは大変なので、そういったソフトウェアのインストールもこの段階で済ませてしまうと良いと思います。

*** アレンジ例

今回はメインの実験で MATLABが必要で、ライセンス管理の自動化が厄介なので、 MATLABのインストールまでを手動でやりました。必要なソフトウェアにライセンス等の問題が全くないのであればこの工程は自動化しても良いと思います。例えば、 Packer で予め必要なマシンイメージを作っておいて、必要な時に必要なだけ Terraform とかでマシンを作って、不要になったらすぐ壊す、ということが可能です。

また、初期設定に手動部分がどうしても必要な場合でも、自動設定の部分と手動設定の部分を分離することで、Packerなどを部分的に用いるワークフローにすることも良いと思います。

** vmctl の設定ファイルを書く

次にvmctlを設定します。vmctlの設定はjsonで書かれた設定ファイル (=~/.vmctl.json=) で行ないます。基本的には 1) インスタンス名、 2) インスタンスの種類 (ec2等)、 3) インスタンス ID、 が書かれたjsonファイルで、例えば以下の様になります。

#+BEGIN_EXAMPLE
[
    {
        "name": "marisa",
        "type": "ec2",
        "instance_id": "i-0fsdfd13c7bf3d6b6",
        "profile": "sample"
    },
    {
        "name": "reimu",
        "type": "virtual_box",
        "instance_id": "95a2dsfdb-0dfbf-40bb-bf15-92df8d07c7dc"
    }
]
#+END_EXAMPLE

インスタンス数が少ない場合は手書きしても大丈夫ですが、多数のインスタンスを扱う場合は設定ファイルを自動で生成したくなると思います。Amazon EC2については 例えば次のコマンドで生成することができます。

#+BEGIN_SRC shell
aws ec2 describe-instances --query 'Reservations[*].Instances[*].[InstanceId,Tags[?Key==`Name`].Value|[0]]|[]' |
    jq --arg profile "$PROFILE" 'map({"type": "ec2", "instance_id": .[0], "name": .[1]})' > ~/.vmctl.json
#+END_SRC

* 実験環境設定パート

次は実験環境設定パートについて説明していきます。

** 実験環境構築用の Ansible playbook を書く

まず始めに実験環境構築用の Ansible playbook を書きます。ここでは、データセットの準備や実験対象のプログラムのコンパイル、実験用Gitレポジトリの準備等に加えて、後で必要となるaws-cliやslackに通知を送るためのスクリプトの設定等も行ないます。細かい内容についてはさておき、例えば以下の様な YAMLファイル で設定を行なうことができます。

#+BEGIN_SRC yaml
  - hosts: aws
    user: ubuntu
    tasks:
      - name: Install required packages
        apt:
          pkg:
            - awscli
            - unzip
            - ...
        become: yes
      
      - name: configure aws-cli
        file:
          dest: ~/.aws/
          state: directory

      - name: configure aws-cli
        copy:
          src: ~/.aws/config
          dest: ~/.aws/config

      - name: configure aws-cli
        copy:
          src: ~/.aws/credentials
          dest: ~/.aws/credentials

      - name: Download and extract the dataset
        unarchive:
          dest: /tmp
          src: http://example.com/dataset.zip
          remote_src: yes

      - name: clone bar-experiments
        git:
          repo: "git@example.com:foo/bar-experiments.git"
          dest: /home/ubuntu/bar-experiments

      - name: setup notif_my_slack
        file:
          dest: ~/bin/
          state: directory

      - name: setup notif_my_slack
        shell: m4 -DHOST=$(/usr/bin/aws ec2 describe-instances --instance-ids  "$(cat /var/lib/cloud/data/instance-id)" --query 'Reservations[*].Instances[*].Tags[?Key==`Name`].Value' | tr -d [] | xargs) /home/ubuntu/bar-experiments/utils/notif_my_slack.m4 > ~/bin/notif_my_slack

      - name: setup notif_my_slack
        file:
          path: ~/bin/notif_my_slack
          mode: '0755'
#+END_SRC

*** =notif_my_slack.m4=

環境設定用のAnsible notebookの中で =notif_my_slack.m4= が出てきたので説明をします。 =notif_my_slack.m4= はm4のコードです。今回m4は =notif_my_slack= というシェルスクリプトを生成するためのプリプロセッサとして使っています。m4自体もチューリング完全なプログラミング言語ですが、今回は単に文字列 =HOST= をEC2でのインスタンス名に置換するためだけに使っています。なお最後の =https://hooks.slack.com/services/<The given ID>= はslackで外部から通知を飛ばす用のURL (Incoming Webhooksのエンドポイント) です。取得法などについては slack, Incoming Webhooks, 等で検索すると詳しい説明が出てくるので省略します。

#+BEGIN_SRC m4
#!/bin/sh

if [ $# -gt 0 ]; then
  curl -X POST -H 'Content-type: application/json' --data '{"text":"'"$*"' from HOST"}' https://hooks.slack.com/services/<The given ID>
else
  curl -X POST -H 'Content-type: application/json'  --data  `"{\"text\":\"###From' HOST###\n$(cat)\"}" https://hooks.slack.com/services/<The given ID>
fi
#+END_SRC

** 実験スクリプトを書く

「実験スクリプトを書く」というとただ一言で終わってしまうので、個人的に採用している実験用Gitレポジトリの構成についても説明します。実験用にGitレポジトリを作っている理由は前述の様に複数マシンで同時に実験した結果を上手い具合にマージできるからですが、できるだけマージ時に衝突しないように図の様なディレクトリ構成を採用しています。ざっくり言うと気をつけている点は以下の点です。

- 各実験に個別のスクリプト等は各実験用のディレクトリに入れる。逆に共通のスクリプト等は =/utils= 以下に格納する
- 各実験にtimestamp付きのIDを割り振って衝突しない様にする
- 実験用スクリプト名は常に =run.sh=
- 各ディレクトリには実験の説明を書いた =README.md= を書く

#+BEGIN_EXAMPLE
├── <20200102-1234-experiment1>
│   ├── README.md
│   ├── run.sh
│   ├── launch.sh
│   ...
├── <20200203-2345-experiment2>
│   ├── README.md
│   ├── run.sh
│   ├── launch.sh
│   ...
└── utils
    ├── setup.sh
    ├── teardown.sh
    ├── notif_my_slack.m4
    ...
#+END_EXAMPLE

それではそれぞれのファイルについて説明していきます。なお、 =notif_my_slack.m4= の説明は \ref-subsection(`実験環境構築用の-ansible-playbook-を書く`); を参照してください。

*** run.sh

=run.sh= は実験用のメインになるスクリプトです。ファイル名を =run.sh= に固定するのは自動化を容易にするためです。複数のスクリプトが欲しい場合はディレクトリを切る運用にしました。 =run.sh= での処理はざっくり書くと以下の様になります。

- 準備用のスクリプトである =setup.sh= (後述) を呼ぶ
- 実験本体の処理
- 終了処理用のスクリプトである =teardown.sh= (後述) を呼ぶ

*** setup.sh

さて、 =setup.sh= は準備用のスクリプトです。とはいえやっている内容は以下の二つだけになります。

- 実験対象のプログラム等、外部で使っているgitレポジトリののバージョンをファイルに保存
- slackに実験開始のお知らせをする

#+BEGIN_SRC sh
#!/bin/sh

git --git-dir ~/<Program>/.git rev-parse HEAD > git-hash

readonly experiment=$(pwd | sed 's:.*/::')

notif_my_slack <<EOF
experiment ${experiment} started.
The arguments: $@
EOF
mkdir -p results
#+END_SRC

*** teardown.sh

次に実験終了時のスクリプト、 =teardown.sh= です。ざっくり言うとやっている内容は以下の三点になります。

- 実験内容を =git commit= する
- slackに実験終了のお知らせをする
- 実験に使ったインスタンスを停止する

#+BEGIN_SRC sh
#!/bin/sh

readonly experiment=$(pwd | sed 's:.*/::')

# Synchronize the filesystem and wait for 60 sec.
sync
sleep 60
git add .
git commit -m "experiment ${experiment} $* finished"
notif_my_slack "experiment_${experiment}_finished"
/usr/bin/aws ec2 stop-instances --instance-ids  "$(cat /var/lib/cloud/data/instance-id)"
#+END_SRC


* 実験パート

次は実験パートについて説明していきます。ここが実験のメインパートですが、これまでにしっかりと準備しているので、やっていることは極々シンプルです。

** 実験に必要なマシンを立てる

まず始めに実験に必要なマシンを立てます。今回既に実験に必要なマシンは構築されているので、 =vmctl= を使ってマシンを立ち上げるだけです。例えば以下の様なコマンドでマシンを立ち上げられます。なお、マシン名が連番だったり共通部分がある場合はシェルのブレース展開 (Brace Expansion) を使うと便利です。

#+BEGIN_SRC sh
vmctl start マシン1 マシン2 ...
#+END_SRC

** マシン上に実験環境を構築する

次にマシン上に実験環境を構築します。具体的には実験用レポジトリやデータセットの準備などを行ないます。とはいえ既にこれらの準備をする Ansible playbook を準備していると思うので、単に Ansible playbookを実行するだけになります。

Ansible を使っていく上で問題になるのがインベントリの管理です。というのも少なくともAmazon EC2のインスタンスは起動する度にグローバルIPアドレスが変わるのでインベントリファイルを事前に作っておく訳には行きません。こんなときのために (?) Dynamic Inventoryという仕組みが Ansible にはありますが、今回は難しいことは考えずに静的なインベントリファイルのIPアドレスの部分を実行前に生成することにしてみます。 例えば次のシェルスクリプトとm4のコードを元にするとインベントリを作れます。やっていることは単に下のm4ファイルの"IP"と書かれた部分を =vmctl= で得られたIPアドレスに置き換えているだけです。

#+BEGIN_SRC sh
  m4 -DIP="$(vmctl ip "$@")" aws_host.m4 > aws_host
#+END_SRC

#+BEGIN_SRC m4
[aws]
IP

[aws:vars]
ansible_ssh_user=ubuntu
ansible_ssh_private_key_file=~/.ssh/id_ecdsa

[all:vars]
ansible_ssh_port=22
#+END_SRC

インベントリが生成されたら Ansible playbookを実行しましょう。

#+BEGIN_SRC sh
ansible-playbook -i aws_host setup.yaml
#+END_SRC

** 実験スクリプトを回す

次に実験スクリプトを回します。前述の様に今回はexpectを使って、SSH越しにリモートインスタンスで実験スクリプトを動かしていきます。実験スクリプトをリモートで動かす際は =nohup= を使っても良いのですが、後で実験スクリプトの様子を確認したくなる場合もあるので、個人的には[[https://www.gnu.org/software/screen/][GNU screen]]を愛用しています。

#+BEGIN_SRC tcl
#!/usr/bin/expect
#****h* utils/run_remote
# NAME
#  run_remote
# DESCRIPTION
#  execute run.sh in a remote machine
#
# USAGE
#  ./run_remote.tcl <ssh arguments> <experiment_id> <run.sh arguments>
#
# EXAMPLE
#  ./run_remote.tcl 127.0.0.1 20190102-1234-test_experiment TEST_ARG
# PORTABILITY
#  We need expect <https://core.tcl-lang.org/expect/index> at /usr/bin/expect.
#******

#****h* run_remote/lshift
# NAME
#  lshift
# DESCRIPTION
#  An implementation of the shift of perl. This implementation is taken from Tcler's Wiki <https://wiki.tcl-lang.org/page/lshift>
#
# USAGE
#  lshift listVar
#
# EXAMPLE
#  lshift argv
#******
proc lshift listVar {
    upvar 1 $listVar l
    set r [lindex $l 0]
    set l [lreplace $l [set l 0] 0]
    return $r
}

if {[llength $argv] < 2} then {
    puts "Error: <ssh arguments> and <experiment_id> are not given"
    puts "Usage: ./run_remote.tcl <ssh arguments> <experiment_id> <arguments>"
    exit 1
}

set host [lshift argv]
set experiment_id [lshift argv]

set timeout 30

eval spawn ssh $host
expect {
    "(yes/no*)?" {
        send "yes\n"
        exp_continue
    }
    "*\\\$" {
        send "screen\n\n"
        expect { 
            "*\\\$" {
                send "cd ./foo-experiments/${experiment_id}\n"
                expect "*\\\$"
                send "./run.sh [join $argv]\n"
                expect "ok*"
            }
        }
    }
}
exit 0
#+END_SRC

* 実験後

最後に実験後の流れについて説明をします。

** =teardown.sh=

まず始めに実験後に自動で行なわれる処理は =teardown.sh= (前述) に書かれている以下の内容ものです。具体的なスクリプトの内容については \ref-subsection(`実験スクリプトを書く`); を参照してください。

- 実験内容を =git commit= する
- slackに実験終了のお知らせをする
- 実験に使ったインスタンスを停止する

** Git レポジトリの同期

次にGitレポジトリを同期させる必要があります。Gitレポジトリの運用方針ですが以下の様にしていきます。

- 基本的に =master= ブランチを使う
- 但し実験後、マージ前の一時的な場合のみ他のブランチを使う

*** Git レポジトリの push

まず始めにGitレポジトリをpushしますが、ここは例によって Ansible で行ないます。ここで重要なことですが、push先のブランチは =tmp= から始まる一時的なもので、hostname が付いていて各インスタンスについて固有なものとなっているということです。なおインベントリは前述のコマンド・スクリプトで生成できます。Gitレポジトリのpushが終わったらインスタンスは不要なので停止させてください (無駄に課金されて勿体ないので)。

#+BEGIN_SRC yaml
- hosts: aws
  tasks:
    - name: Install required packages
      apt:
        pkg:
          - git
      become: yes

    - name: push to the remote
      command: 
        cmd: git push origin master:tmp_{{ ansible_hostname }}
        chdir: /home/ubuntu/bar-experiments
#+END_SRC

*** Gitレポジトリの merge

次にGitレポジトリのmergeを手元のマシンで行ないますが、早い話単に =git merge= するだけです。一つずつやっても良いですが、 =tmp= から始まるリモートレポジトリを全部 merge させたいのであれば例えば次のコマンドで行なえます。

#+BEGIN_SRC sh
git branch -a | grep remotes/origin | grep tmp | sed 's:remotes/origin/::' | xargs -I{} git merge {}
#+END_SRC

Gitレポジトリのmergeを終えて不要になったブランチは例えば次のコマンドで消せます。こちらは並列実行しても問題ないので、 =xargs= の =-P= オプション (POSIXには入っていないですが =GNU xargs= を始めとして多くの =xargs= が =-P= に対応しています) を使っても大丈夫です。

#+BEGIN_SRC sh
git branch -a | grep remotes/origin | grep tmp | sed 's:remotes/origin/::' | xargs -I{} git push origin :{}
#+END_SRC

* POSTPONED COMMENT 実験解析パート

** 解析対象のファイル名指定 YAML

** sync

#+BEGIN_SRC yaml
- hosts: aws
  tasks:
    - name: Install required packages
      apt:
        pkg:
          - git
      become: yes

    - name: push to the remote
      command: 
        cmd: git push origin master:tmp_{{ ansible_hostname }}
        chdir: /home/ubuntu/bar-experiments
#+END_SRC


** 解析 Makefile

* POSTPONED COMMENT 全体のワークフロー (フローチャートを書く)

- (ここからマシン構築パート) マシンを作成・設定する (起動させっぱなしだとお金が勿体ないので停止させておく)
   - 今回ここは完全に手動なので特に言うことなし
- vmctl の設定ファイルを構成する
- (ここから実験環境設定パート。人が書く) 実行したい実験の環境を ansible playbookで書く
   - 例えばデータセット、実装などをダウンロードする
   - このplaybookを各実験毎に書くか、一回書いて使い回すかは、各実験で何が変わるかに依る
     - 例えば環境は同じで色々なパラメタに対して実験を回すのであれば、一回書いて使い回せる
     - 旧実装と新実装を比較するなら、少なくともansibleのgitモジュールなどで実装をダウンロードする箇所は使い回せない
       - 上手く作って変数にしておけば大丈夫かも?
   - 諸々のデータはGitHub等十分強いリモートからダウンロードするのが良い
     - そうしないと帯域の関係でローカルからデータを送る部分がボトルネックになりうる
- 実験スクリプトを書く
   - メインパートは、例えば「調査対象のコマンド・関数を実行させて、その前後の時間を計測」など
   - 今回はshell scriptを使ったが他の方法でも良い
   - 実装の版が特に規定されていない (例えばGitのmasterを使う)場合は gitの版のハッシュ値をテキストで保存しておく
   - 実験の開始・終了をslackにお知らせする
   - 実験結果をgit commitする
   - 実験の終了後に自動でインスタンスを停止する
- (ここから実験パート。スクリプトを回す) インスタンスを立てる
   - vmctl を使う
   - Bashの brace expansionを使うと便利 (POSIX標準ではないので、例えばdashでは使えないらしい)
     - 例えば machine1, machine2, machine3, machine4, machine5 を立てるなら =vmctl start machine{1..5}= で良い
     - 詳しくは Bashマニュアル(i.e., =man bash=)のBrace Expansionを参照
- インスタンス上に実験環境を構築する
   - 要するにansibleを叩く
   - ansibleのhostファイルを生成する必要がある
   - リモートでsshを使う場合はssh-agentのforward agentが必要な場合がある
     - https://qiita.com/isaoshimizu/items/84ac5a0b1d42b9d355cf
   - known_hosts問題
     - =export ANSIBLE_HOST_KEY_CHECKING=False=
- 実験スクリプトを回す
   - expect + sshで各インスタンスで実験スクリプトを回す
   - screenを使うことで、ローカルからの接続が切れても問題ないようにする
     - nohupを使っても良いが、screenだと万が一標準エラー出力とかを見たくなったときに簡単に対応できる
- (ここから実験解析パート) インスタンスを立てる
- Gitで実験結果をsyncさせる
- 解析スクリプトを回す


* $\diamond$ (Eventually) 回予告

*いかがだったでしょうか!!*

今回は複数マシンでの実験を Ansible とかでシュっとした話のうち、実験を回して結果を回収するところまで説明をしました。今回の方法が最適解であるかはさておき、自分で並列実験システムを構築するときのたたき台になると幸いです。

さて、実験を回したら当然結果を解析する必要があります。解析パートは実験が並列であるかどうかとはあまり関係ないですが、自動解析も結構工夫のしがいがあるところです。ということで $\diamond$ (Eventually) 回 は解析パートと題して、シェルスクリプトでの実験結果解析を説明する予定です。


